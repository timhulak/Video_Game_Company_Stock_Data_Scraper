{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "### Web Scraper:\n",
    " - I created a list of the companies that we are focusing on, and then programmed a loop that will append the search url with each name in the list.\n",
    " - While looping throug the list, the scraper will scrape the article headline and description from the Forbes website and store it in a variable.\n",
    "\n",
    "### Sentiment Analysis:\n",
    " - Using the NLTK Vader Sentiment Intensity Analyzer, I was able to use the headline and description variables to perform a sentiment analysis on both the headline itself, and the article description.\n",
    " - To keep things clean and easily analyzed, I chose to store the sentiment analysis ratings in separate dictionaries, and then pull only the 'compound' sentiment score for each to store in the main 'gcDict' dictionary.\n",
    " - After running the sentiment analysis, I coded a simple conditional statement to convert the compound sentiment score into an easily readable 'positive', 'negative', or 'neutral' sentiment for easy future analysis.\n",
    " \n",
    "### MongoDB:\n",
    " - As each iteration of the loop was being performed, I stored all of the relevant information in the 'gcDict' dictionary.\n",
    " - At the end of each iteration, I pushed the dictionry to the 'gameCollection' collection in a db named 'gamesDB' .\n",
    " - Once each iteration of the loop begins, the dictionary is cleared to save memory and keep the code clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT STUFF HERE\n",
    "import pymongo\n",
    "import datetime\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BROWSER MAGIC\n",
    "def init_browser():\n",
    "    executable_path = {\"executable_path\": \"chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECT TO MONGODB AND ACCESS THE 'GAMESDB' DATABASE\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.gameDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST OF STOCK TICKERS FOR EACH COMPANY\n",
    "stockList = ['NTDOY', 'EA', 'UBSFY', 'ATVI', 'SGAMY', 'TTWO', 'SQNXF', 'NCBDF']\n",
    "\n",
    "# LIST OF GAME COMAPNIES\n",
    "gcList = ['Nintendo',\n",
    "          'Electronic Arts', \n",
    "          'Ubisoft',\n",
    "          'Activision Blizzard',\n",
    "          'Sega Sammy Holdings',\n",
    "          'Take-two Interactive',\n",
    "          'Square Enix',\n",
    "          'Bandai Namco']\n",
    "\n",
    "x = 0\n",
    "\n",
    "#  ------------------------------------------------------\n",
    "#                      STOCK SCRAPER\n",
    "#  ------------------------------------------------------\n",
    "\n",
    "for y in stockList:\n",
    "    # SLEEP TIMER\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # INITIALIZE BROWSER\n",
    "    browser = init_browser()\n",
    "\n",
    "    # CREATE EMPTY DICTIONARY TO STORE STOCK INFORMATION\n",
    "    stockDict = {}  \n",
    "    \n",
    "    # URL CONFIG FOR YAHOO FINANCE\n",
    "    url = f'https://finance.yahoo.com/quote/{y}?p={y}&.tsrc=fin-srch'\n",
    "    browser.visit(url)\n",
    "\n",
    "    # SET TIMER\n",
    "    time.sleep(2)\n",
    "\n",
    "    # BROWSER/SOUP INFO\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "    \n",
    "    # SCRAPE THE STOCK PRICE\n",
    "    stockPrice = soup.find('span', class_='Trsdu(0.3s) Fw(b) Fz(36px) Mb(-4px) D(ib)').text.strip()\n",
    "    \n",
    "    # UPDATE STOCK DICTIONARY WITH COMPNY NAME AND STOCK TICKER\n",
    "    stockDict.update( {'company' : gcList[x]} )\n",
    "    stockDict.update( {'stock_ticker' : y} )    \n",
    "    \n",
    "    # UPDATE STOCK DICTIONARY WITH STOCK INFO\n",
    "    stockDict.update( {'stock_price' : stockPrice} )\n",
    "    \n",
    "    # CLOSE THE BROWSER WHEN COMPLETE\n",
    "    browser.quit()\n",
    "    \n",
    "#  ------------------------------------------------------\n",
    "#     HEADLINE/ARTICLE SCRAPER AND SENTIMENT ANALYSIS\n",
    "#  ------------------------------------------------------\n",
    "    \n",
    "    # SLEEP TIMER\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # INITIALIZE BROWSER\n",
    "    browser = init_browser()\n",
    "\n",
    "    # CREATE EMPTY DICTIONARIES TO STORE INFORMATION\n",
    "    gcDict = {}\n",
    "    headlineAnalysis = {}\n",
    "    bodyAnalysis = {}\n",
    "    \n",
    "    # URL CONFIG FOR FORBES\n",
    "    url = f'https://www.forbes.com/search/?q={gcList[x]}'\n",
    "    browser.visit(url)\n",
    "\n",
    "    # SET TIMER\n",
    "    time.sleep(2)\n",
    "\n",
    "    # BROWSER/SOUP INFO\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    # SCRAPE THE FIRST HEADLINE\n",
    "    getHeadline = soup.find('a', class_='stream-item__title').text.strip()\n",
    "\n",
    "    # SCRAPE THE ARTICLE DESCRIPTION\n",
    "    getDesc = soup.find('div', class_='stream-item__description').text.strip()\n",
    "\n",
    "    # SENTIMENT ANALYSIS\n",
    "    sia = SIA() \n",
    "    headline_score = sia.polarity_scores(getHeadline)\n",
    "    body_score = sia.polarity_scores(getDesc)\n",
    "    gcDict.update({'headline' : getHeadline})\n",
    "    headlineAnalysis.update(headline_score)\n",
    "    gcDict['headline_sentiment_score'] = headlineAnalysis['compound']\n",
    "    gcDict.update( {\"headline_sentiment\": \n",
    "        \"positive\" if headlineAnalysis['compound'] > 0.3 else \n",
    "        \"negative\" if headlineAnalysis['compound'] < -0.3 else \n",
    "        \"neutral\"\n",
    "    })\n",
    "    gcDict.update( {'article_description' : getDesc} )\n",
    "    bodyAnalysis.update(body_score)\n",
    "    gcDict['article_sentiment_score'] = bodyAnalysis['compound']\n",
    "    gcDict.update( {\"article_sentiment\": \n",
    "        \"positive\" if bodyAnalysis['compound'] > 0.3 else \n",
    "        \"negative\" if bodyAnalysis['compound'] < -0.3 else \n",
    "        \"neutral\"\n",
    "    })\n",
    "        \n",
    "    # CLOSE THE BROWSER WHEN COMPLETE\n",
    "    browser.quit()\n",
    "    \n",
    "    # MERGE THE ARTICLE/SENTIMENT DICTIONARY INTO THE STOCK DICTIONARY\n",
    "    stockDict.update(gcDict)\n",
    "    \n",
    "    # PUSH THE DICT TO THE DATABASE\n",
    "    db.gameCollection.insert_one(stockDict)\n",
    "    \n",
    "    x += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
